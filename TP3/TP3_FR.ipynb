{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INF 8215 - Intelligence artif.: méthodes et algorithmes \n",
    "## Automne 2018 - TP3 - Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Date de rendu: 6 Décembre**\n",
    "\n",
    "**Fichiers à rendre:**\n",
    "    * TP3_FR.ipynb complété\n",
    "    * SoftmaxClassifier.py complété\n",
    "    * test_prediction.csv le fichier de résultat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Le but de ce TP est de vous donner un aperçu du déroulement général d'un projet de machine learning tout en vous familiarisant avec des librairies python adaptées.\n",
    "\n",
    "\n",
    "Dans la première partie, vous implémenterez un algorithme de classification multiclasse appelé **softmax regression** à l'aide uniquement de la bibliothèque **numpy** et l'intégrerez à la bibliothèque **scikit-learn**.\n",
    "\n",
    "Dans la deuxième partie, vous prendrez connaissance du **dataset** utilisé pour ce projet. Et vous serez amenés à effectuer le **preprocessing** de ces données pour qu'elles soient utilisables dans les algorithmes de machine learning classiques. Vous utiliserez les bibliothèques **pandas** et **scikit-learn**.\n",
    "\n",
    "Enfin, dans la troisième partie, vous comparerez l'efficacité du modèle que vous avez implémenté avec d'autres modèles déjà implémentés dans **sklearn**. Puis vous tenterez d'améliorer les performances de l'algorithme sélectionné.\n",
    "\n",
    "Pour enfin soumettre vos résultats sur la plateforme **kaggle**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation\n",
    "\n",
    "Pour installer **pandas** et **scikit-learn** le plus simple est de télécharger et d'installer **Anaconda** qui regroupe les packages les plus utilisés pour le calcul scientifique et la science des données.\n",
    "\n",
    "Vous trouverez la distribution ici : https://www.anaconda.com/download/#linux .\n",
    "\n",
    "Assurez-vous d'avoir la version **20.0** de **scikit-learn**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus 1: Compétition (2 points)\n",
    "\n",
    "Quand vous aurez terminé le TP, vous pourrez soumettre vos prédictions sur **kaggle**, vous obtiendrez votre performance en terme de **log loss**.\n",
    "Vous pouvez ensuite me communiquer ce résultat par mail (laurent.boucaud@polymtl.ca) et me joindre votre fichier de prédiction sur l'ensemble de test(pour vérification).\n",
    "\n",
    "Une conversation dans le forum sera créée pour tenir à jour le meilleur score obtenu par une des équipes du cours.\n",
    "\n",
    "Tant qu'aucun forum n'est créé, **ne m'envoyez pas vos performances si elles sont supérieures à 0.8 de log loss**.\n",
    "\n",
    "Une fois le premier meilleur score affiché dans le forum, **ne me communiquez vos résultats que si votre log loss est inférieure au précédent meilleur score**.\n",
    "\n",
    "Le nombre de points obtenus sera proportionnel au classement des équipes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Softmax Regression (10 points)\n",
    "\n",
    "Dans cette partie vous implémenterez **softmax regression** la variante de **logistic regression** qui permet d'effectuer de la classification pour un nombre de classe supérieur à 2.\n",
    "\n",
    "Le code à compléter se trouve dans le fichier **SoftmaxClassifier.py**. \n",
    "\n",
    "**Pour cet exercice, la contrainte est d'utiliser uniquement la bibliothèque numpy**\n",
    "\n",
    "## Encapsulation avec sklearn\n",
    "\n",
    "La classe **SoftmaxClassifier** hérite des classes **BaseEstimator** et **ClassifierMixin** de **scikit-learn** ce qui nous permettra d'utiliser facilement avec notre classifier les outils fournis par scikit-learn dans la suite du TP.\n",
    "\n",
    "Pour la compatibilité, le classifier implémente obligatoirement les méthodes:\n",
    "\n",
    "* **fit**: responsable de l'entraînement du modèle\n",
    "* **predict_proba**: permet de prédire la probabilité de chaque classe pour chaque exemple du dataset fourni.\n",
    "* **predict**: permet de prédire la classe pour chaque exemple du dataset fourni.\n",
    "* **score**: permet de quantifier l'écart entre les classes prédites et les classes réelles pour le dataset fourni\n",
    "\n",
    "\n",
    "## Train/Test set:\n",
    "\n",
    "Quand on veut tester les performances de l'apprentissage d'un algorithme de machine learning, on **ne le teste pas sur les données utilisées pour l'apprentissage**.\n",
    "\n",
    "En effet, ce qui nous intéresse c'est que notre algorithme soit **capable de généraliser** ses prédictions à des données qu'il n'a **jamais vu**.\n",
    "\n",
    "Pour illustrer, si on teste un algorithme sur les données d'entrainement, on teste sa capacité à **apprendre par coeur** le dataset et non à **généraliser**.\n",
    "\n",
    "Par conséquent, quand on reçoit un nouveau dataset, la première chose à faire et de le **diviser en deux parties**: un ensemble d'**entraînement** (**70-80%** du dataset) et un ensemble de **test**(**20-30%** du dataset).\n",
    "\n",
    "Tous les algorithmes de **traitement des données** et d'apprentissage devront être appris uniquement sur l'ensemble d'entraînement et appliqués ensuite sur l'ensemble de test.\n",
    "\n",
    "Cela garantit l'absence de connaissances préalables de l'ensemble de test lors de l'entrainement.\n",
    "\n",
    "## Gradient descent\n",
    "\n",
    "La descente de gradient est un algorithme qui permet trouver la solution optimale d'un certains nombre de problèmes. Le principe est le suivant: on définit une **fonction de coût J**  qui caractérise le problème.\n",
    "Cette fonction dépend d'un ensemble de **paramètres $\\theta$ **. La descente de gradient cherche à **minimiser** la fonction de coût en **modifiant itérativement** les paramètres.\n",
    "\n",
    "### Gradient\n",
    "\n",
    "Le gradient de la fonction de coûts pour un $\\theta$ donné, correspond à la direction dans laquelle il faut modifier $\\theta$ pour réduire la valeur de la fonction de coût. \n",
    "\n",
    "La fonction de coût est minimale quand le gradient est nul.\n",
    "\n",
    "Concrètement, on initialize $\\theta$ aléatoirement, et on effectue à chaque itération un pas pour réduire la fonction de coût jusqu'à convergence de l'algorithme à un minimum.\n",
    "\n",
    "### Learning rate\n",
    "\n",
    "Le taux d'apprentissage correspond à la taille du pas que l'on va effectuer dans la direction du gradient.\n",
    "Plus il est grand, plus la convergence est rapide mais il y a un risque que l'algorithme diverge.\n",
    "\n",
    "Plus il est petit, plus la convergence est lente.\n",
    "\n",
    "### Batch gradient descent\n",
    "\n",
    "Il existe plusieurs algorithmes de descente de gradient. Nous utiliserons Batch gradient descent.\n",
    "\n",
    "Dans cet algorithme, avant de mettre à jour $\\theta$, on calcule les gradients sur l'ensemble des exemples d'entraînement.\n",
    "\n",
    "### Epoch\n",
    "\n",
    "Il s'agit d'un pas de la descente de gradient, soit une unique mise à jour de gradient.\n",
    "\n",
    "### Bias/Variance tradeoff\n",
    "\n",
    "Lorsqu'on entraine un algorithme de machine learning on cherche un équilibre entre **biais** et **variance**.\n",
    "\n",
    "Un modèle avec un **biais fort**, est un modèle qui est **trop simple** pour la structure donnée considérée (modèle linéaire pour données quadratiques), cela limite la capacité du modèle à généraliser. On appelle aussi le biais **underfitting**.\n",
    "\n",
    "Un modèle avec une **variance élevée** signifie qu'il est sensible aux petites variations dans les données d'entrainement, cela correspond à l'**overfitting**, c'est-à-dire que le modèle est trop proche de la structure de l'ensemble d'entrainement ce qui **limite sa capacité à généraliser**.\n",
    "\n",
    "Un modèle avec un **biais important** aura une **mauvaise performance** sur l'ensemble d'**entraînement**.\n",
    "Un modèle avec une **variance importante** aura une performance bien **moins bonne** sur l'ensemble de **test** que sur l'ensemble d'**entrainement**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot-encoding\n",
    "\n",
    "En machine learning pour représenter un vecteur de données catégoriques, on utilise le one-hot encoding.\n",
    "\n",
    "Pour un vecteur comportant 5 exemples et 3 catégories différentes, on le représente sous forme d'une matrice de taille 5 par 3. Cette matrice est entièrement remplie de 0 sauf à l'indice correspondant au numéro de la classe pour chaque exemple.\n",
    "\n",
    "\n",
    "Par exemple\n",
    "$ y = \\left(\\begin{array}{cc} \n",
    "1 \\\\\n",
    "1 \\\\\n",
    "2 \\\\\n",
    "3 \\\\\n",
    "2 \\\\\n",
    "\\end{array}\\right) $\n",
    "\n",
    "devient:\n",
    "\n",
    "$ yohe =  \\left(\\begin{array}{cc} \n",
    "1. & 0. & 0.\\\\\n",
    "1. & 0. & 0.\\\\\n",
    "0. & 1. & 0.\\\\\n",
    "0. & 0. & 1.\\\\\n",
    "0. & 1. & 0.\\\\\n",
    "\\end{array}\\right) $\n",
    "\n",
    "\n",
    "#### Question 1 (1 point)\n",
    "Implémentez  la fonction  **_one_hot**  dans SoftmaxClassifier.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrice de poids\n",
    "\n",
    "Soit $ X_{m * n} $ la matrice d'exemple et $ \\Theta _{n*K} $ la matrice de poids avec:\n",
    "\n",
    "* **m** le nombre d'exemples\n",
    "* **n** le nombre de features\n",
    "* **k** le nombre de classes\n",
    "\n",
    "Il est d'usage d'ajouter une colonne supplémentaire à X, cette colonne est remplie de 1. Pour prendre en compte ce changement, il faut rajouter une ligne à la matrice $\\Theta$.\n",
    "\n",
    "On obtient X_bias$_{m*(n+1)}$ et $ \\Theta _{(n+1)*K} $\n",
    "\n",
    "\n",
    "Intuitivement, à chaque classe K est associée une colonne de $\\theta$.\n",
    "\n",
    "On note $\\theta_k$ le vecteur de dimension n+1 la colonne de poids associée à la prédiction de la classe k.\n",
    "\n",
    "$\\Theta$ = [$\\theta_0$,$\\theta_1$... $\\theta_k$ ... $\\theta_n$ ]\n",
    "\n",
    "Ainsi $ z = x * \\Theta $ donne un vecteur de dimension K qui correspond aux **logits** associés à x pour chacune des classes.\n",
    "\n",
    "#### Question 2 (1 point)\n",
    "Dans la fonction  **fit**  dans SoftmaxClassifier.py instanciez X_bias et initialisez $\\Theta$ aléatoirement. (ligne 74)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Softmax\n",
    "\n",
    "On veut convertir le vecteur de logits **z** obtenu dans la partie précédente, en un **vecteur de probabilité**.\n",
    "\n",
    "Pour cela on définit la **fonction softmax**:\n",
    "\n",
    "$$ \\hat{p_x}^k = softmax(z)_k = \\frac{exp(z_k)}{\\sum_{\\substack{1<j<K}} exp(z_j)} $$\n",
    "\n",
    "Intuitivement, pour un logit de z, $z_k$, on prend l'exponentielle de cette valeur et on la divise par la somme des exponentielles de chaque logit du vecteur **z**. On obtient  $\\hat{p_x}^k$ la probabilité que l'exemple **x** appartienne à la classe **k**.\n",
    "\n",
    "On réitère l'opération pour chaque logit du vecteur **z**. \n",
    "\n",
    "On obtient ainsi un vecteur de probabilités $\\hat{p_x}$ pour un exemple **x**. \n",
    "\n",
    "La division permet de rendre la somme des termes du vecteur $\\hat{p_x}$ égale à 1 ce qui est indispensable dans le cadre des probabilités.\n",
    "\n",
    "#### Question 3 (1 point)\n",
    "Implémentez  la fonction  **_softmax**  dans SoftmaxClassifier.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 4 (1 point)\n",
    "En utilisant la fonction **_softmax** de la question 3, implémentez  les fonctions  **predict_proba** et **predict**  dans SoftmaxClassifier.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fonction de coût Log loss\n",
    "\n",
    "Soit la fonction de coût log loss (ou cross entropy):\n",
    "\n",
    "$$ J( \\Theta) = \\frac{-1}{m}\\sum_{\\substack{1<i<m}} \\sum_{\\substack{1<k<K}} y_k^i log( \\hat{p_k}^i ) $$\n",
    "\n",
    "avec:\n",
    "* **K** le nombre de classes\n",
    "* **m** le nombre d'exemples dans les données\n",
    "* $ \\hat{p_k}^i  $  la probabilité que l'exemple i soit de la classe k\n",
    "* $y_k^i$ vaut 1 si la classe cible de l'exemple i est k, 0 sinon\n",
    "\n",
    "**Détail d'implémentation:** La fonction n'est pas définie pour des valeurs de probabilité de 0. ou 1., il faut donc s'assurer que étant donné $\\epsilon$, les probabilités sont comprises dans [$\\epsilon$, 1. - $\\epsilon$].\n",
    "#### Question 5 (1 point)\n",
    "Implémentez  la fonction  **_cost_function**  dans SoftmaxClassifier.py en prenant en compte le **détail d'implémentation** (variable self.eps) et utilisez-la pour calculer la variable **loss** dans la fonction **fit** (ligne 84)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient de la fonction de coût\n",
    "\n",
    "Le **gradient de J** par rapport à la classe k (par rapport à $\\theta_k$) est :\n",
    "\n",
    "\n",
    "$$ \\Delta_{\\theta_k}J( \\Theta) = \\frac{1}{m} \\sum_{\\substack{1<i<m}}( \\hat{p_k}^i - y_k^i)x^i  $$\n",
    "\n",
    "avec:\n",
    "* **K** le nombre de classes\n",
    "* **m** le nombre d'exemples dans les données\n",
    "* $ \\hat{p_k}^i  $  la probabilité que l'exemple i soit de la classe k\n",
    "* $y_k^i$ vaut 1 si la classe cible de l'exemple i est k, 0 sinon\n",
    "\n",
    "Sous **forme matricielle**, on peut écrire le **gradient de J par rapport à $\\Theta$**:\n",
    "$$ \\Delta_J( \\Theta) = \\frac{1}{m} X_{bias}^T *( \\hat{p} - y_{ohe}) $$\n",
    "\n",
    "avec:\n",
    "* $\\hat{p}$ la matrice de probabilité prédite pour chaque example et pour chaque classe\n",
    "* $y_{ohe}$ la version one-hot de y\n",
    "* $X_{bias}^T$  la matrice transposée de $X_{bias}$\n",
    "* **\\*** le produit matriciel\n",
    "\n",
    "#### Question 6 (1 point)\n",
    "Implémentez  la fonction  **_get_gradient**  dans SoftmaxClassifier.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mise à jour des poids\n",
    "\n",
    "Quand le gradient a été calculé, il faut mettre à jour les poids avec ces gradients.\n",
    "\n",
    "$$ \\Theta  = \\Theta - \\gamma \\Delta J( \\Theta) $$\n",
    "\n",
    "\n",
    "avec:\n",
    "* $\\Theta$ la matrice de poids\n",
    "* $\\gamma$  le taux d'apprentissage\n",
    "* $\\Delta J( \\Theta)$ le gradient de $J( \\Theta)$ selon $\\Theta$\n",
    "\n",
    "#### Question 7 (1 point)\n",
    "Mettez à jour la variable **self.theta_** dans la fonction **fit**  dans SoftmaxClassifier.py (ligne 85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularization\n",
    "\n",
    "Pour limiter l'**overfitting**, on utilise la régularisation, il s'agit d'ajouter un terme à la fonction de coût $J( \\Theta)$.\n",
    "\n",
    "Ce terme va ajouter des contraintes sur les poids du modèle lors de l'entrainement.\n",
    "Nous allons utiliser la régularisation **L2** :\n",
    "\n",
    "$$ L2(\\Theta) = \\alpha \\sum_{\\substack{1<=i<n}} \\sum_{\\substack{0<=k<K}} \\theta_{i,k}^2 $$ \n",
    "\n",
    "avec:\n",
    "\n",
    "* $\\alpha$ le coefficient de régularisation\n",
    "\n",
    "**Remarque:** La première somme ne commence pas à 0 mais à 1 parce qu'on ne régularise pas les poids associés à la colonne de biais de X.\n",
    "\n",
    "Le fait d'ajouter ce terme conduit le modèle à apprendre les données tout en gardant ses poids le plus petit possible.\n",
    "\n",
    "\n",
    "\n",
    "#### Question 8 (1 point)\n",
    "Modifiez les fonctions  **_get_gradient** et **_cost_function** pour prendre en compte la régularisation lorsque le booléen self.regularization est vrai  dans SoftmaxClassifier.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 9 (1 point)\n",
    "\n",
    "Le terme de régularisation est utilisé uniquement pendant l'entraînement. Quand on veut évaluer la performance du modèle **après entrainement**, on utilise la fonction de coût **non-régulée**.\n",
    "\n",
    "Implémentez la fonction **score** qui permet d'évaluer la qualité de la prédiction **après entrainement** dans SoftmaxClassifier.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Early stopping\n",
    "\n",
    "Un trop grand nombre d'**epoch** peut résulter en **overfitting**.\n",
    "Pour pallier à ce problème, on peut utiliser le mécanisme d'**early stopping**.\n",
    "Il s'agit d'arrêter l'entraînement si la différence de la fonction de coût entre deux **epochs consécutives** est inférieure à un **seuil**.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### Question 10 (1 point)\n",
    "\n",
    "Finissez d'implémenter la fonction **fit** en y ajoutant le mécanisme d'**early stopping**  quand le booléen **self.early_stopping** est vrai le seuil est donné par la variable **self.threshold**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test de la solution:\n",
    "\n",
    "Le code ci-dessous importe le dataset de classification multiclasse **iris** disponible sur sklearn. Les données sont divisées en deux parties, l'ensemble d'entraînement et l'ensemble de test, puis elles sont normalisées.\n",
    "\n",
    "Le classifier implémenté dans le fichier **SoftmaxClassifier.py** est importé puis entrainé sur l'ensemble d'entrainement et testé sur l'ensemble de test.\n",
    "\n",
    "Le but de cette partie est juste de vérifier votre implémentation **quand vous êtes sûrs que votre code fonctionne**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# load dataset\n",
    "data,target =load_iris().data,load_iris().target\n",
    "\n",
    "# split data in train/test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split( data, target, test_size=0.33, random_state=42)\n",
    "\n",
    "# standardize columns using normal distribution\n",
    "# fit on X_train and not on X_test to avoid Data Leakage\n",
    "s = StandardScaler()\n",
    "X_train = s.fit_transform(X_train)\n",
    "X_test = s.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SoftmaxClassifier import SoftmaxClassifier\n",
    "\n",
    "# import the custom classifier\n",
    "cl = SoftmaxClassifier(regularization=True)\n",
    "\n",
    "# train on X_train and not on X_test to avoid overfitting\n",
    "train_p = cl.fit_predict(X_train,y_train)\n",
    "test_p = cl.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si vous obtenez des valeurs relativement proches pour l'ensemble de test et d'entrainement, et qu'elles sont au moins supérieures à 0.8, votre modèle devrait être correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train : (0.8952702702702703, 0.8941176470588236, 0.8936304393525333, None)\n",
      "test : (0.8985507246376812, 0.8444444444444444, 0.8387216648086214, None)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "# display precision, recall and f1-score on train/test set\n",
    "print(\"train : \"+ str(precision_recall_fscore_support(y_train, train_p,average = \"macro\")))\n",
    "print(\"test : \"+ str(precision_recall_fscore_support(y_test, test_p,average = \"macro\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data preprocessing (8 points)\n",
    "\n",
    "##  Kaggle \n",
    "Kaggle est un site dédié au machine learning. On y retrouve un grand nombre de dataset.\n",
    "Des compétitions sont organisées par des organisations. Ces dernières fournissent un dataset et un objectif. Les \"kagglers\" qui participent à ces compétitions soumettent leurs résultats en ligne. Il y a souvent des prix ou des emplois pour ceux qui obtiennent les meilleurs résultats.\n",
    "\n",
    "Il s'agit d'un bon moyen pour développer ses compétences en machine learning sur des vrais datasets.\n",
    "\n",
    "Vous pouvez créer un compte si vous voulez comparer vos résultats à ceux déjà en ligne pour la dataset que nous allons étudier.\n",
    "\n",
    "Vous pouvez créer un compte ici: https://www.kaggle.com/\n",
    "\n",
    "\n",
    "## Austin Animal Center Shelter Animal Outcomes dataset\n",
    "Le dataset que nous utiliserons est le \"Animal Outcomes dataset\" disponible à l'adresse suivante: https://www.kaggle.com/c/shelter-animal-outcomes.\n",
    "\n",
    "Il s'agit d'un problème de **classification multiclasse** des animaux sont recueillis dans un refuge après avoir été abandonnés, le but est de prédire la manière dont ils vont \"quitter \" le lieu:\n",
    "* Adoption\n",
    "* Retour au propriétaire\n",
    "* Décès \n",
    "* Euthanasie\n",
    "* Transfert à un autre centre\n",
    "\n",
    "Pour plus d'informations sur les données, rendez-vous sur kaggle.\n",
    "\n",
    "## Déroulement d'un projet de machine learning\n",
    "\n",
    "Le but de la suite de ce TP est de vous faire étudier une version simplifiée d'un projet complet de machine learning:\n",
    "\n",
    "1. Nettoyage des données, traitement des valeurs manquantes\n",
    "2. Mise en forme des données pour pouvoir les utiliser dans les algorithmes de machine learning\n",
    "3. Feature engineering: transformation ou combinaison de features entre elles\n",
    "4. Comparaison des performances des différents choix effectués lors du traîtement des données\n",
    "5. Comparaison des performances de différents modèles (dont celui implémenté en première partie)\n",
    "6. Optimisation des hyper-paramètres\n",
    "\n",
    "## Scikit-learn\n",
    "http://scikit-learn.org/stable/\n",
    "\n",
    "Il s'agit d'une bibliothèque de machine learning et data mining, elle propose des outils pour l'analyse et le traîtement des données,  des algorithmes classiques de machine learning comme les réseaux de neuronnes, la régression logistique, les SVM ou autre, enfin des outils permettant de comparer les modèles entre eux comme la cross validation.\n",
    "\n",
    "## Pandas\n",
    "\n",
    "Une bibliothèque permettant de stocker des données et de les manipuler facilement\n",
    "\n",
    "Les deux éléments de base de pandas sont le dataframe et la serie.\n",
    "\n",
    "https://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.DataFrame.html\n",
    "\n",
    "## Data processing tutorial\n",
    "\n",
    "**Avant de continuer le TP**, familiarisez-vous avec le **pré-traitement des données**, **pandas** et **scikit-learn**, un tutoriel est disponible dans le fichier: **data_processing_tutorial.ipynb**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "#### Chargement de l'ensemble d'entraînement et de l'ensemble de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "PATH = \"data/\"\n",
    "X_train = pd.read_csv(PATH + \"train.csv\")\n",
    "X_test = pd.read_csv(PATH + \"test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Suppression de colonnes inutiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.drop(columns = [\"OutcomeSubtype\",\"AnimalID\"])\n",
    "X_test, ID = X_test.drop(columns = [\"ID\"]),X_test[\"ID\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = X_train.drop(columns = [\"OutcomeType\"]),X_train[\"OutcomeType\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5 premiers exemples de l'ensemble d'entraînement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>DateTime</th>\n",
       "      <th>AnimalType</th>\n",
       "      <th>SexuponOutcome</th>\n",
       "      <th>AgeuponOutcome</th>\n",
       "      <th>Breed</th>\n",
       "      <th>Color</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hambone</td>\n",
       "      <td>2014-02-12 18:22:00</td>\n",
       "      <td>Dog</td>\n",
       "      <td>Neutered Male</td>\n",
       "      <td>1 year</td>\n",
       "      <td>Shetland Sheepdog Mix</td>\n",
       "      <td>Brown/White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Emily</td>\n",
       "      <td>2013-10-13 12:44:00</td>\n",
       "      <td>Cat</td>\n",
       "      <td>Spayed Female</td>\n",
       "      <td>1 year</td>\n",
       "      <td>Domestic Shorthair Mix</td>\n",
       "      <td>Cream Tabby</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pearce</td>\n",
       "      <td>2015-01-31 12:28:00</td>\n",
       "      <td>Dog</td>\n",
       "      <td>Neutered Male</td>\n",
       "      <td>2 years</td>\n",
       "      <td>Pit Bull Mix</td>\n",
       "      <td>Blue/White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2014-07-11 19:09:00</td>\n",
       "      <td>Cat</td>\n",
       "      <td>Intact Male</td>\n",
       "      <td>3 weeks</td>\n",
       "      <td>Domestic Shorthair Mix</td>\n",
       "      <td>Blue Cream</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2013-11-15 12:52:00</td>\n",
       "      <td>Dog</td>\n",
       "      <td>Neutered Male</td>\n",
       "      <td>2 years</td>\n",
       "      <td>Lhasa Apso/Miniature Poodle</td>\n",
       "      <td>Tan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Name             DateTime AnimalType SexuponOutcome AgeuponOutcome  \\\n",
       "0  Hambone  2014-02-12 18:22:00        Dog  Neutered Male         1 year   \n",
       "1    Emily  2013-10-13 12:44:00        Cat  Spayed Female         1 year   \n",
       "2   Pearce  2015-01-31 12:28:00        Dog  Neutered Male        2 years   \n",
       "3      NaN  2014-07-11 19:09:00        Cat    Intact Male        3 weeks   \n",
       "4      NaN  2013-11-15 12:52:00        Dog  Neutered Male        2 years   \n",
       "\n",
       "                         Breed        Color  \n",
       "0        Shetland Sheepdog Mix  Brown/White  \n",
       "1       Domestic Shorthair Mix  Cream Tabby  \n",
       "2                 Pit Bull Mix   Blue/White  \n",
       "3       Domestic Shorthair Mix   Blue Cream  \n",
       "4  Lhasa Apso/Miniature Poodle          Tan  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5 premiers exemples de l'ensemble de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>DateTime</th>\n",
       "      <th>AnimalType</th>\n",
       "      <th>SexuponOutcome</th>\n",
       "      <th>AgeuponOutcome</th>\n",
       "      <th>Breed</th>\n",
       "      <th>Color</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Summer</td>\n",
       "      <td>2015-10-12 12:15:00</td>\n",
       "      <td>Dog</td>\n",
       "      <td>Intact Female</td>\n",
       "      <td>10 months</td>\n",
       "      <td>Labrador Retriever Mix</td>\n",
       "      <td>Red/White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cheyenne</td>\n",
       "      <td>2014-07-26 17:59:00</td>\n",
       "      <td>Dog</td>\n",
       "      <td>Spayed Female</td>\n",
       "      <td>2 years</td>\n",
       "      <td>German Shepherd/Siberian Husky</td>\n",
       "      <td>Black/Tan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gus</td>\n",
       "      <td>2016-01-13 12:20:00</td>\n",
       "      <td>Cat</td>\n",
       "      <td>Neutered Male</td>\n",
       "      <td>1 year</td>\n",
       "      <td>Domestic Shorthair Mix</td>\n",
       "      <td>Brown Tabby</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pongo</td>\n",
       "      <td>2013-12-28 18:12:00</td>\n",
       "      <td>Dog</td>\n",
       "      <td>Intact Male</td>\n",
       "      <td>4 months</td>\n",
       "      <td>Collie Smooth Mix</td>\n",
       "      <td>Tricolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Skooter</td>\n",
       "      <td>2015-09-24 17:59:00</td>\n",
       "      <td>Dog</td>\n",
       "      <td>Neutered Male</td>\n",
       "      <td>2 years</td>\n",
       "      <td>Miniature Poodle Mix</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Name             DateTime AnimalType SexuponOutcome AgeuponOutcome  \\\n",
       "0    Summer  2015-10-12 12:15:00        Dog  Intact Female      10 months   \n",
       "1  Cheyenne  2014-07-26 17:59:00        Dog  Spayed Female        2 years   \n",
       "2       Gus  2016-01-13 12:20:00        Cat  Neutered Male         1 year   \n",
       "3     Pongo  2013-12-28 18:12:00        Dog    Intact Male       4 months   \n",
       "4   Skooter  2015-09-24 17:59:00        Dog  Neutered Male        2 years   \n",
       "\n",
       "                            Breed        Color  \n",
       "0          Labrador Retriever Mix    Red/White  \n",
       "1  German Shepherd/Siberian Husky    Black/Tan  \n",
       "2          Domestic Shorthair Mix  Brown Tabby  \n",
       "3               Collie Smooth Mix     Tricolor  \n",
       "4            Miniature Poodle Mix        White  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5 premiers exemples de l'attribut à prédire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Return_to_owner\n",
       "1         Euthanasia\n",
       "2           Adoption\n",
       "3           Transfer\n",
       "4           Transfer\n",
       "Name: OutcomeType, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Travail demandé\n",
    "\n",
    "Pour vous faire gagner du temps, une partie des colonnes (Name,DateTime,color) ont déjà été traitées.\n",
    "\n",
    "\n",
    "En vous appuyant sur le tutoriel fourni, vous devez écrire un pipeline complet de transformation pour chacune des colonnes restantes du dataset (AgeuponOutcome,AnimalType,SexuponOutcome, Breed).\n",
    "\n",
    "Vous êtes **libres** de vos choix, mais vous devez les **justifer** colonne par colonne.\n",
    "Par exemple, vous pouvez choisir de combiner des colonnes entre elles, de séparer une colonne en plusieurs ou encore d'éliminer complètement une colonne si vous le justifiez correctement.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La partie déjà prétraitée du dataset est chargée dans **X_train1** et **X_test1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1 = pd.read_csv(\"data/train_preprocessed.csv\")\n",
    "X_test1 = pd.read_csv(\"data/test_preprocessed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Color</th>\n",
       "      <th>HasName</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.973624</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.421532</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.973624</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.471381</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.868974</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Color  HasName  Month  Day  Hour\n",
       "0  0.973624      1.0    2.0  1.0   3.0\n",
       "1 -1.421532      1.0   10.0  1.0   2.0\n",
       "2  0.973624      1.0    1.0  3.0   2.0\n",
       "3 -1.471381      0.0    7.0  1.0   3.0\n",
       "4 -0.868974      0.0   11.0  1.0   2.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le reste du dataset que vous devez traiter est:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Question 11: AgeuponOutcome (1 point)\n",
    "\n",
    "Nous conservons la colonnes telle qu'elle. Les valeurs textuelles ne pouvant être traitées par le modèle, nous les convertissons en nombre de semaines afin d'avoir des données numériques. De cette manière plus le chiffre est grand plus son age est grand. Un viel animal a plus de chance de mourir ou d'être euthanisié."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_num_duration(text):\n",
    "    if not isinstance(text, str):\n",
    "        return 12\n",
    "    else:\n",
    "        num, duration = text.split(\" \")\n",
    "        if 'year' in duration:\n",
    "            return int(num)*12\n",
    "        elif 'week' in duration:\n",
    "            return int(num)*12/52\n",
    "        return int(num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 12: AnimalType (1 point)\n",
    "\n",
    "La colonne AnimalType est considérée telle qu'elle et nous effectuons un \"one hot encoding\" sur les valeurs texteuelles afin de les transformer en valeurs numériques utilisables par le modèle. Pour cette colonne et pour les suivantes, nous utilisons le \"one hot encoding\" plutôt que le \"label encoding\". \n",
    "Le \"label encoding\" introduit en effet plusieurs valeurs numériques dans une même colonne ce qui est mal interprété par le modèle qui y voit une notion d'ordre (0 < 1 < 2 < ... ) alors que ce n'est pas le cas. Le \"one hot encoding\" ne présente pas ce problème. Il divise la colonne en plusieurs autres, une pour chaque \"catégorie\" (ici type d'animal) et les nombres sont remplacés par des 1 ou des 0 dans les colonnes corespondantes à sa \"catégorie\".\n",
    "\n",
    "C'est pour cette raison qu'il n'y a pas de fonction nécessaire ici, le onehotencoding est effectué directment dans le pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 13: SexuponOutcome (1 point)\n",
    "\n",
    "Nous conservons la colonnes telle qu'elle. Nous effectuons dans un premier temps une uniformisation des données puis nous appliquons un \"one hot enconding\" afin de transformer les données textuelles en données numériques traitables par le modèle. Un animal traité avait surement un maitre auparavant il a peut etre plus de chance d'être retrouvé donc on garde toutes les catégories. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_gender_neutra(text):\n",
    "    if not isinstance(text,str) or 'Unknown' in text :\n",
    "        return \"Unknown\"\n",
    "    return text.replace(\" \",\"_\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 14: Breed (1 point)\n",
    "\n",
    "Ici, plus de traitement est effectué. Première on retournera si l'animal est un Mix ou si l'animal  est pure, le tout sera onehotencode par la suite. Un animal pu peu avoir plus de chance d'être adopté ou retrouvé. La deuxième fonction sépare les deux races, si c'est un mix et retourne None si on ne connait pas la deuxième. Retourne Pure comme deuxième race quand l'animal est pure sang. \n",
    "\n",
    "Par la suite un traitement est effectué, on regarde toutes les races comptabilisées et on garde celles qui ont plus de 25 apparitons dans le modèle. On mettra à None les races de respectant pas le seuil. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_pure(text):\n",
    "    if \"Mix\" in text:\n",
    "        return 'Mixed'\n",
    "    if '/' in text:\n",
    "        to_ret = text.split(\"/\")\n",
    "        return 'Mixed'\n",
    "    return 'Pure'\n",
    "\n",
    "def parse_breed(text):\n",
    "    if \"Black/Tan\" in text:\n",
    "        text = text.replace(\"Black/Tan\",\"Black_Tan\")\n",
    "    if \"Mix\" in text:\n",
    "        return (' '.join(text.split(\" \")[:-1]),\"None\")\n",
    "    if '/' in text:\n",
    "        to_ret = text.split(\"/\")\n",
    "        return (to_ret[0],to_ret[1])\n",
    "    return (text,\"Pure\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "PATH = \"data/\"\n",
    "X_train = pd.read_csv(PATH + \"train.csv\")\n",
    "X_test = pd.read_csv(PATH + \"test.csv\")\n",
    "\n",
    "breed_train = X_train.apply(lambda row: pd.Series(  parse_breed(row[\"Breed\"])  ), axis = 1  )\n",
    "breed_train.columns = [\"first\",'second']\n",
    "breed_test = X_test.apply(lambda row: pd.Series(  parse_breed(row[\"Breed\"])  ), axis = 1  )\n",
    "breed_test.columns = [\"first\",'second']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Mix                      22298.0\n",
       "Shetland                    37.0\n",
       "Sheepdog                    40.0\n",
       "Shorthair                11114.0\n",
       "Domestic                 10388.0\n",
       "Bull                      2295.0\n",
       "Pit                       2204.0\n",
       "Poodle                     453.0\n",
       "Lhasa                       70.0\n",
       "Apso/Miniature               8.0\n",
       "Terrier/Chihuahua           85.0\n",
       "Cairn                      142.0\n",
       "American                   351.0\n",
       "Terrier                   1376.0\n",
       "Miniature                  635.0\n",
       "Schnauzer                  226.0\n",
       "Yorkshire                  226.0\n",
       "Great                      174.0\n",
       "Pyrenees                   141.0\n",
       "Angora                       7.0\n",
       "Coat                        73.0\n",
       "Retriever                 1937.0\n",
       "Flat                        48.0\n",
       "Heeler                      64.0\n",
       "Queensland                  61.0\n",
       "Hound/Boxer                  2.0\n",
       "Plott                       96.0\n",
       "Shepherd                  1141.0\n",
       "German                     857.0\n",
       "Staffordshire              223.0\n",
       "                          ...   \n",
       "Kelpie/Shiba                 1.0\n",
       "Tzu/Cavalier                 1.0\n",
       "Coat/German                  1.0\n",
       "Spaniel/Toy                  1.0\n",
       "Bulldog/Dachshund            1.0\n",
       "Spitz/Chow                   1.0\n",
       "Beagle/Whippet               1.0\n",
       "Boxer/Mastiff                1.0\n",
       "Longhair/Russian             1.0\n",
       "Pointer/Staffordshire        1.0\n",
       "Papillon/Australian          1.0\n",
       "Pinscher/Maltese             1.0\n",
       "Husky/Catahoula              1.0\n",
       "Terrier/Welsh                1.0\n",
       "Vizsla/Rhod                  1.0\n",
       "Shorthair/British            1.0\n",
       "Whippet/Borzoi               1.0\n",
       "Terrier/Plott                1.0\n",
       "Shorthair/Parson             1.0\n",
       "Italiano                     1.0\n",
       "Spinone                      1.0\n",
       "Collie/Rottweiler            1.0\n",
       "Collie/Alaskan               1.0\n",
       "Dalmatian/Boxer              1.0\n",
       "Corgi/Basset                 1.0\n",
       "Poodle/Italian               1.0\n",
       "Boxer/Neapolitan             1.0\n",
       "Bulldog/English              1.0\n",
       "Vizsla/Boxer                 1.0\n",
       "Boxer/German                 1.0\n",
       "Length: 1074, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "X_train.Breed.apply(lambda x: pd.value_counts(x.split(\" \"))).sum(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "breed_dict = {}\n",
    "for i in range(len(breed_train)):\n",
    "    if breed_train.iloc[i,0] in breed_dict.keys():\n",
    "        breed_dict[breed_train.iloc[i,0]]+=1\n",
    "    else:\n",
    "        breed_dict[breed_train.iloc[i,0]]=1\n",
    "    if breed_train.iloc[i,0] != breed_train.iloc[i,1]:\n",
    "        if breed_train.iloc[i,1] in breed_dict.keys():\n",
    "            breed_dict[breed_train.iloc[i,1]]+=1\n",
    "        else:\n",
    "            breed_dict[breed_train.iloc[i,1]]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "seuil = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_breed1(text):\n",
    "    if \"Black/Tan\" in text:\n",
    "        text = text.replace(\"Black/Tan\",\"Black Tan\")\n",
    "    if \"Mix\" in text:\n",
    "        if ' '.join(text.split(\" \")[:-1]) in breed_dict.keys():\n",
    "            if breed_dict[' '.join(text.split(\" \")[:-1])]>seuil:\n",
    "                return ' '.join(text.split(\" \")[:-1])\n",
    "        return 'None'\n",
    "    if '/' in text:\n",
    "        to_ret = text.split(\"/\")\n",
    "        if to_ret[0] in breed_dict.keys():\n",
    "            if breed_dict[to_ret[0]]>seuil:\n",
    "                return to_ret[0]\n",
    "        return 'None'\n",
    "    if text in breed_dict.keys():\n",
    "        if breed_dict[text]>seuil:\n",
    "            return text\n",
    "    return 'None'    \n",
    "\n",
    "def parse_breed2(text):\n",
    "    if \"Black/Tan\" in text:\n",
    "        text = text.replace(\"Black/Tan\",\"Black Tan\")\n",
    "    if \"Mix\" in text:\n",
    "        return \"None\"\n",
    "    if '/' in text:\n",
    "        to_ret = text.split(\"/\")\n",
    "        if to_ret[1] in breed_dict.keys():\n",
    "            if breed_dict[to_ret[1]]>seuil:\n",
    "                return to_ret[1]\n",
    "        return 'None'\n",
    "    if text in breed_dict.keys():\n",
    "        return 'Pure'\n",
    "    return 'None' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On enleve les races ne respectant pas le seuil. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_remove = []\n",
    "for k in breed_dict.keys():\n",
    "    if breed_dict[k] <= seuil:\n",
    "        to_remove.append(k)\n",
    "for k in to_remove:\n",
    "    breed_dict.pop(k, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "breed_cate1 = np.array(list(breed_dict.keys()),dtype=np.str).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "breed_encode = OneHotEncoder('auto', sparse = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneHotEncoder(categorical_features=None, categories=None,\n",
       "       dtype=<class 'numpy.float64'>, handle_unknown='error',\n",
       "       n_values='auto', sparse=False)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "breed_encode.fit(breed_cate1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On utilisera ces catégories pour le onehotencoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "breed_cate2 = breed_encode.categories_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline\n",
    "**Question 15: Complétez pipeline ci-dessous (4 points)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing import TransformationWrapper\n",
    "from preprocessing import LabelEncoderP\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "# Age\n",
    "pipeline_num = Pipeline([\n",
    "    ('AgeuponOutcome', TransformationWrapper(transformation = parse_num_duration)),\n",
    "])\n",
    "\n",
    "\n",
    "# Type\n",
    "pipeline_type = Pipeline([\n",
    "    (\"encode\",OneHotEncoder(categories = 'auto', sparse = False))\n",
    "])\n",
    "\n",
    "# Sexe\n",
    "pipeline_gender = Pipeline([\n",
    "    ('SexuponOutcome', TransformationWrapper(transformation = parse_gender_neutra)),\n",
    "    (\"encode\",OneHotEncoder(categories = 'auto', sparse = False))\n",
    "])\n",
    "\n",
    "# Breed\n",
    "pipeline_breed1 = Pipeline([\n",
    "    ('first', TransformationWrapper(transformation = parse_breed1)),\n",
    "    (\"encode\",OneHotEncoder(categories = breed_cate2, sparse = False))\n",
    "])\n",
    "\n",
    "# Breed\n",
    "pipeline_breed2 = Pipeline([\n",
    "    ('first', TransformationWrapper(transformation = parse_breed2)),\n",
    "    (\"encode\",OneHotEncoder(categories = breed_cate2, sparse = False))\n",
    "])\n",
    "\n",
    "# Breed\n",
    "pipeline_pure = Pipeline([\n",
    "    ('fsi', TransformationWrapper(transformation = parse_pure)),\n",
    "    (\"encode\",OneHotEncoder(categories = 'auto', sparse = False))\n",
    "\n",
    "])\n",
    "\n",
    "\n",
    "full_pipeline = ColumnTransformer([\n",
    "        (\"Age\", pipeline_num, [\"AgeuponOutcome\"]),\n",
    "        (\"Type\", pipeline_type, [\"AnimalType\"]),\n",
    "        (\"Sex\", pipeline_gender, [\"SexuponOutcome\"]),\n",
    "        ('pure', pipeline_pure, [\"Breed\"]),\n",
    "        ('fsi1', pipeline_breed1, [\"Breed\"]),\n",
    "        ('fsi2', pipeline_breed2, [\"Breed\"]),\n",
    "\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lancez le pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La liste des colomnes pour les races pour breed1 et breed2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = list(breed_dict.keys())+ [s + '1' for s in list(breed_dict.keys())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['age','cat','dog','s1','s2','s3','s4','s5','mixed','pure']+results\n",
    "\n",
    "\n",
    "X_train_prepared = pd.DataFrame(full_pipeline.fit_transform(X_train),columns=column_names)\n",
    "X_test_prepared = pd.DataFrame(full_pipeline.transform(X_test),columns=column_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>cat</th>\n",
       "      <th>dog</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>mixed</th>\n",
       "      <th>pure</th>\n",
       "      <th>...</th>\n",
       "      <th>Pug1</th>\n",
       "      <th>Golden Retriever1</th>\n",
       "      <th>Pembroke Welsh Corgi1</th>\n",
       "      <th>Toy Poodle1</th>\n",
       "      <th>Boston Terrier1</th>\n",
       "      <th>Parson Russell Terrier1</th>\n",
       "      <th>Mastiff1</th>\n",
       "      <th>Carolina Dog1</th>\n",
       "      <th>Soft Coated Wheaten Terrier1</th>\n",
       "      <th>Alaskan Husky1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.692308</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 186 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         age  cat  dog   s1   s2   s3   s4   s5  mixed  pure       ...        \\\n",
       "0  12.000000  0.0  1.0  0.0  0.0  1.0  0.0  0.0    1.0   0.0       ...         \n",
       "1  12.000000  1.0  0.0  0.0  0.0  0.0  1.0  0.0    1.0   0.0       ...         \n",
       "2  24.000000  0.0  1.0  0.0  0.0  1.0  0.0  0.0    1.0   0.0       ...         \n",
       "3   0.692308  1.0  0.0  0.0  1.0  0.0  0.0  0.0    1.0   0.0       ...         \n",
       "4  24.000000  0.0  1.0  0.0  0.0  1.0  0.0  0.0    1.0   0.0       ...         \n",
       "\n",
       "   Pug1  Golden Retriever1  Pembroke Welsh Corgi1  Toy Poodle1  \\\n",
       "0   0.0                0.0                    0.0          0.0   \n",
       "1   0.0                0.0                    0.0          0.0   \n",
       "2   0.0                0.0                    0.0          0.0   \n",
       "3   0.0                0.0                    0.0          0.0   \n",
       "4   0.0                0.0                    0.0          0.0   \n",
       "\n",
       "   Boston Terrier1  Parson Russell Terrier1  Mastiff1  Carolina Dog1  \\\n",
       "0              0.0                      0.0       0.0            0.0   \n",
       "1              0.0                      0.0       0.0            0.0   \n",
       "2              0.0                      0.0       0.0            0.0   \n",
       "3              0.0                      0.0       0.0            0.0   \n",
       "4              0.0                      0.0       0.0            0.0   \n",
       "\n",
       "   Soft Coated Wheaten Terrier1  Alaskan Husky1  \n",
       "0                           0.0             0.0  \n",
       "1                           0.0             0.0  \n",
       "2                           0.0             0.0  \n",
       "3                           0.0             0.0  \n",
       "4                           0.0             0.0  \n",
       "\n",
       "[5 rows x 186 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_prepared.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>cat</th>\n",
       "      <th>dog</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>mixed</th>\n",
       "      <th>pure</th>\n",
       "      <th>...</th>\n",
       "      <th>Pug1</th>\n",
       "      <th>Golden Retriever1</th>\n",
       "      <th>Pembroke Welsh Corgi1</th>\n",
       "      <th>Toy Poodle1</th>\n",
       "      <th>Boston Terrier1</th>\n",
       "      <th>Parson Russell Terrier1</th>\n",
       "      <th>Mastiff1</th>\n",
       "      <th>Carolina Dog1</th>\n",
       "      <th>Soft Coated Wheaten Terrier1</th>\n",
       "      <th>Alaskan Husky1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 186 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  cat  dog   s1   s2   s3   s4   s5  mixed  pure       ...        Pug1  \\\n",
       "0  10.0  0.0  1.0  1.0  0.0  0.0  0.0  0.0    1.0   0.0       ...         0.0   \n",
       "1  24.0  0.0  1.0  0.0  0.0  0.0  1.0  0.0    1.0   0.0       ...         1.0   \n",
       "2  12.0  1.0  0.0  0.0  0.0  1.0  0.0  0.0    1.0   0.0       ...         0.0   \n",
       "3   4.0  0.0  1.0  0.0  1.0  0.0  0.0  0.0    1.0   0.0       ...         0.0   \n",
       "4  24.0  0.0  1.0  0.0  0.0  1.0  0.0  0.0    1.0   0.0       ...         0.0   \n",
       "\n",
       "   Golden Retriever1  Pembroke Welsh Corgi1  Toy Poodle1  Boston Terrier1  \\\n",
       "0                0.0                    0.0          0.0              0.0   \n",
       "1                0.0                    0.0          0.0              0.0   \n",
       "2                0.0                    0.0          0.0              0.0   \n",
       "3                0.0                    0.0          0.0              0.0   \n",
       "4                0.0                    0.0          0.0              0.0   \n",
       "\n",
       "   Parson Russell Terrier1  Mastiff1  Carolina Dog1  \\\n",
       "0                      0.0       0.0            0.0   \n",
       "1                      0.0       0.0            0.0   \n",
       "2                      0.0       0.0            0.0   \n",
       "3                      0.0       0.0            0.0   \n",
       "4                      0.0       0.0            0.0   \n",
       "\n",
       "   Soft Coated Wheaten Terrier1  Alaskan Husky1  \n",
       "0                           0.0             0.0  \n",
       "1                           0.0             0.0  \n",
       "2                           0.0             0.0  \n",
       "3                           0.0             0.0  \n",
       "4                           0.0             0.0  \n",
       "\n",
       "[5 rows x 186 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_prepared.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Concaténation des deux parties du dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2 = pd.concat([X_train1,X_train_prepared], axis = 1)\n",
    "X_test2 = pd.concat([X_test1,X_test_prepared], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Color</th>\n",
       "      <th>HasName</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Hour</th>\n",
       "      <th>age</th>\n",
       "      <th>cat</th>\n",
       "      <th>dog</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>...</th>\n",
       "      <th>Pug1</th>\n",
       "      <th>Golden Retriever1</th>\n",
       "      <th>Pembroke Welsh Corgi1</th>\n",
       "      <th>Toy Poodle1</th>\n",
       "      <th>Boston Terrier1</th>\n",
       "      <th>Parson Russell Terrier1</th>\n",
       "      <th>Mastiff1</th>\n",
       "      <th>Carolina Dog1</th>\n",
       "      <th>Soft Coated Wheaten Terrier1</th>\n",
       "      <th>Alaskan Husky1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.973624</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.421532</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.973624</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.471381</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.868974</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 191 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Color  HasName  Month  Day  Hour        age  cat  dog   s1   s2  \\\n",
       "0  0.973624      1.0    2.0  1.0   3.0  12.000000  0.0  1.0  0.0  0.0   \n",
       "1 -1.421532      1.0   10.0  1.0   2.0  12.000000  1.0  0.0  0.0  0.0   \n",
       "2  0.973624      1.0    1.0  3.0   2.0  24.000000  0.0  1.0  0.0  0.0   \n",
       "3 -1.471381      0.0    7.0  1.0   3.0   0.692308  1.0  0.0  0.0  1.0   \n",
       "4 -0.868974      0.0   11.0  1.0   2.0  24.000000  0.0  1.0  0.0  0.0   \n",
       "\n",
       "        ...        Pug1  Golden Retriever1  Pembroke Welsh Corgi1  \\\n",
       "0       ...         0.0                0.0                    0.0   \n",
       "1       ...         0.0                0.0                    0.0   \n",
       "2       ...         0.0                0.0                    0.0   \n",
       "3       ...         0.0                0.0                    0.0   \n",
       "4       ...         0.0                0.0                    0.0   \n",
       "\n",
       "   Toy Poodle1  Boston Terrier1  Parson Russell Terrier1  Mastiff1  \\\n",
       "0          0.0              0.0                      0.0       0.0   \n",
       "1          0.0              0.0                      0.0       0.0   \n",
       "2          0.0              0.0                      0.0       0.0   \n",
       "3          0.0              0.0                      0.0       0.0   \n",
       "4          0.0              0.0                      0.0       0.0   \n",
       "\n",
       "   Carolina Dog1  Soft Coated Wheaten Terrier1  Alaskan Husky1  \n",
       "0            0.0                           0.0             0.0  \n",
       "1            0.0                           0.0             0.0  \n",
       "2            0.0                           0.0             0.0  \n",
       "3            0.0                           0.0             0.0  \n",
       "4            0.0                           0.0             0.0  \n",
       "\n",
       "[5 rows x 191 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Model selection (2 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encodage de la classe cible sous forme d'entiers pour l'utiliser\n",
    "avec les algorithmes de scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Adoption' 'Died' 'Euthanasia' 'Return_to_owner' 'Transfer']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "target_label = LabelEncoder()\n",
    "y_train_label = target_label.fit_transform(y_train)\n",
    "print(target_label.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble de validation\n",
    "Pour comparer différents modèles entre eux, on ne peut pas utiliser\n",
    "l'ensemble de test, sinon on serait tenté de garder le modèle correspondant le mieux à l'ensemble de test ce qui pourrait conduire à l'overfitting.\n",
    "\n",
    "Il est d'usage de créer un nouvel ensemble de la taille de l'ensemble de test, l'ensemble de **validation**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-validation\n",
    "\n",
    "La cross-validation est une méthode utile pour comparer la performance de différents modèles de machine learning **sans créer d'ensemble de validation**.\n",
    "\n",
    "Il existe différents types de cross-validation, la procédure la plus classique est la suivante:\n",
    "* Diviser aléatoirement l'ensemble d'entraînement en deux parties (90%/10% par exemple).\n",
    "* Entraîner le modèle sur la plus grande partie, et le tester sur l'autre partie.\n",
    "* Recommencer n fois\n",
    "* Calculer la moyenne et l'écart type des résultats\n",
    "\n",
    "Les avantages sont les suivants:\n",
    "* Considérer la totalité de l'ensemble d'entraînement pour l'évaluation (sans se priver de l'ensemble de validation)\n",
    "* Obtenir l'écart-type des résultats permet une meilleure évaluation de la précision du modèle.\n",
    "\n",
    "L'inconvénient principal est le temps de calcul, étant donné que l'on effectue l'apprentissage du modèle plusieurs fois, cette méthode peut être impossible pour des datasets contenant un grand nombre d'exemple (> 10e5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus 2: StratifiedKFold (1 point)\n",
    "\n",
    "En observant la distribution des classes de l'attribut cible (à l'aide des fonctions de visualisation de pandas), justifiez l'utilisation de l'objet **StratifiedKFold** de sklearn pour la division de l'ensemble d'entraînement lors de cross-validation en comparaison à une méthode pûrement **aléatoire**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Adoption           10769\n",
       "Transfer            9422\n",
       "Return_to_owner     4786\n",
       "Euthanasia          1555\n",
       "Died                 197\n",
       "Name: OutcomeType, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train=pd.DataFrame(y_train)\n",
    "y_train['OutcomeType'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comme on peut le voir ci dessus, la distribution des classes dans le dataset est loin d'être uniforme, une séparation pûrement aléatoire risque de faire en sorte que la training set contienne, par exemple très peu de cas mort alors que le test set pourrait presque tous les contenir. Ainsi le modèle ne pourrait pas bien représenter ces cas. StratifiedKFold permet de maintenir la distribution des classes dans le test set et dans le training set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Question 16: (1 point)\n",
    "\n",
    "\n",
    "**Choisir au moins deux modèles permettant la classification multiclasse sur sklearn en plus du modèle implémenté dans la première partie du TP**.\n",
    "\n",
    "**Complétez la fonction compare qui effectue la crossvalidation pour différents modèles et différentes métriques, et renvoie la liste des moyennes et écart-types pour chacune des métriques, pour chacun des modèles. **\n",
    "\n",
    "**En vous basant sur les différentes métriques, concluez quant au modèle le plus performant.**\n",
    "\n",
    "Evaluez les modèles pour les différentes métriques proposées:\n",
    "* **log loss**: c'est la métrique d'évaluation de kaggle\n",
    "* **precision**: correspond à la qualité de la prédiction, le nombre de classes correctement prédites par le nombre de prédiction total\n",
    "* **recall**: le nombre d'éléments appartenant à une classe, identifiés comme tel, divisé par le nombre total des éléments de cette classe.\n",
    "* **f-score**: une moyenne de la precision et du recall\n",
    "\n",
    "**Remarque: precision et recall sont deux mesures complémentaires pour l'évaluation d'un modèle de classification multi-classe.**\n",
    "\n",
    "Dans le cas d'une classification binaire avec un déséquilibre de la classe cible important, (90%/10%), en évaluant le résultat de la classification avec l'accuracy (nombre de prédictions correctes divisé par le nombre de prédictions total), on peut obtenir un très bon score (90% d'accuracy) en choisissant de prédire systématiquement la classe majoritaire.\n",
    "\n",
    "Dans un tel cas, la precision serait élevée de même, mais le recall serait très bas , nous indiquant la médiocrité de notre modèle.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import *\n",
    "def compare(models,X_train,y_train,nb_runs):\n",
    "    losses = np.empty((len(models),len(scoring)))\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.33, random_state=42)\n",
    "    ## Il n'est pas logique devaluer la performance des differents modeles sur leur donnees d'entrainement\n",
    "    ## Nous avons decide de split les donnes a meme la fonction puisque celle-ci ne prends en entree que les\n",
    "    ## donnees d'entrainement. Ca nous a permit de confirmer que Decision Trees avait un probleme d'overfit.\n",
    "    print('Models: \\n')\n",
    "    for i in range(len(models)):\n",
    "        clf=models[i]\n",
    "        print(clf)\n",
    "        clf.fit(X_train,y_train)\n",
    "        y_pred_proba=clf.predict_proba(X_test)\n",
    "        y_pred=clf.predict(X_test)\n",
    "        losses[i,:]=[log_loss(y_test,y_pred_proba),\n",
    "                     precision_score(y_test,y_pred,average='macro',labels=np.unique(y_pred)),\n",
    "                     recall_score(y_test,y_pred,average='macro',labels=np.unique(y_pred)),\n",
    "                     f1_score(y_test,y_pred,average='macro',labels=np.unique(y_pred))]\n",
    "    \n",
    "    print('log_loss | precision_score | recall_score |f1_score \\n')\n",
    "    return losses,X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models: \n",
      "\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
      "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
      "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "       silent=True, subsample=1)\n",
      "SoftmaxClassifier(alpha=100, early_stopping=True, eps=1e-05, lr=0.1,\n",
      "         n_epochs=1000, regularization=True, threshold=1e-10)\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best')\n",
      "log_loss | precision_score | recall_score |f1_score \n",
      "\n",
      "[[ 0.82121855  0.63790651  0.51448998  0.52603109]\n",
      " [12.41195256  0.64150614  0.54017554  0.34488716]\n",
      " [14.12168983  0.4063203   0.4087536   0.40732278]]\n"
     ]
    }
   ],
   "source": [
    "from SoftmaxClassifier import SoftmaxClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "nb_run = 3\n",
    "\n",
    "models = [\n",
    "    XGBClassifier(),\n",
    "    SoftmaxClassifier(),\n",
    "    DecisionTreeClassifier()\n",
    "    \n",
    "]\n",
    "\n",
    "scoring = ['log_loss', 'precision_score','recall_score','f1_macro']\n",
    "# scoring[1](y_train_label,y_train_label,average='macro')\n",
    "[losses,Xtrain, Xtest, ytrain, ytest]=compare(models,X_train2,y_train_label,nb_run)\n",
    "print(losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 17: Matrice de confusion (0.5 point)\n",
    "\n",
    "La matrice de confusion A est telle que $A_{i,j}$ correspond au nombre d'exemples de la classe i classifié comme appartenant à la classe j.\n",
    "\n",
    "Entrainez le modèle sélectionné sur la totalité de l'ensemble d'entraînement.\n",
    "A l'aide de la matrice de confusion et de la distribution des classes, analysez plus en détail les performances du modèle choisi et justifiez les."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train selected model\n",
    "selected_model = XGBClassifier()\n",
    "\n",
    "# y_pred = selected_model.fit_predict(X_train,y_train_label)#### Le modele choisi n'a pas de fonction fit_predict\n",
    "# Nous avons decide de split les donnees en test et train set, de fit le modele et devaluer la matrice de confusion\n",
    "# sur y_pred venant du test set\n",
    "\n",
    "selected_model.fit(Xtrain,ytrain)\n",
    "ypred=selected_model.predict(Xtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Matrice de confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Adoption</th>\n",
       "      <th>Died</th>\n",
       "      <th>Euthanasia</th>\n",
       "      <th>Return_to_owner</th>\n",
       "      <th>Transfer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Adoption</th>\n",
       "      <td>3078</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>354</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Died</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Euthanasia</th>\n",
       "      <td>85</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>130</td>\n",
       "      <td>228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Return_to_owner</th>\n",
       "      <td>742</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>691</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Transfer</th>\n",
       "      <td>823</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>283</td>\n",
       "      <td>1971</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Adoption  Died  Euthanasia  Return_to_owner  Transfer\n",
       "Adoption             3078     0           1              354       144\n",
       "Died                    4     0           3                5        44\n",
       "Euthanasia             85     0          63              130       228\n",
       "Return_to_owner       742     0           2              691       142\n",
       "Transfer              823     0          28              283      1971"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "pd.DataFrame(confusion_matrix(ytest, ypred), columns = target_label.classes_, index = target_label.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Distribution des classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Adoption' 'Died' 'Euthanasia' 'Return_to_owner' 'Transfer']\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "print(target_label.classes_)\n",
    "pd.Series(y_train_label).hist()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus 3: Optimisation des hyper-paramètres (1 point)\n",
    "\n",
    "Les hyper-paramètres sont les paramètres fixés avant la phase d'apprentissage. Pour optimiser les performances du modèle, on peut sélectionner les meilleurs hyper-paramètres.\n",
    "\n",
    "A l'aide de sklearn, optimisez les hyper-paramètres du modèle que vous avez sélectionné et montrez que les performances ont été améliorées.\n",
    "Vous pouvez utiliser par exemple: **GridSearchCV**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "param1 = {'max_depth': [8,9,10],\n",
    "          'n_estimators':[80,100,120],\n",
    "          'eta': [0.08,0.1,0.12],\n",
    "          'objective': ['multi:softprob'],\n",
    "          'num_class': [5],\n",
    "         'eval_metric': ['mlogloss'],\n",
    "          'subsample': [0.8,0.9],\n",
    "          'colsample_bytree': [0.8,0.9],\n",
    "          'silent':[1],\n",
    "          'n_jobs':[12]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iter_search = 50\n",
    "random_search = RandomizedSearchCV(XGBClassifier(n_estimators=100, objective= 'multi:softprob', num_class= 5, silent=True), param_distributions=param1,\n",
    "                                   n_iter=n_iter_search, cv=StratifiedKFold(n_splits=5, random_state=1, shuffle=True),verbose=1,scoring=\"neg_log_loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 250 out of 250 | elapsed: 80.2min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=StratifiedKFold(n_splits=5, random_state=1, shuffle=True),\n",
       "          error_score='raise-deprecating',\n",
       "          estimator=XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, num_class=5, objective='multi:softprob',\n",
       "       random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "       seed=None, silent=True, subsample=1),\n",
       "          fit_params=None, iid='warn', n_iter=50, n_jobs=None,\n",
       "          param_distributions={'max_depth': [8, 9, 10], 'n_estimators': [80, 100, 120], 'eta': [0.08, 0.1, 0.12], 'objective': ['multi:softprob'], 'num_class': [5], 'eval_metric': ['mlogloss'], 'subsample': [0.8, 0.9], 'colsample_bytree': [0.8, 0.9], 'silent': [1], 'n_jobs': [12]},\n",
       "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "          return_train_score='warn', scoring='neg_log_loss', verbose=1)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search.fit(X_train2, y_train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'subsample': 0.8,\n",
       " 'silent': 1,\n",
       " 'objective': 'multi:softprob',\n",
       " 'num_class': 5,\n",
       " 'n_jobs': 12,\n",
       " 'n_estimators': 100,\n",
       " 'max_depth': 8,\n",
       " 'eval_metric': 'mlogloss',\n",
       " 'eta': 0.08,\n",
       " 'colsample_bytree': 0.8}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 18: Soumission (0.5 point)\n",
    "\n",
    "Enfin, effectuez la prédiction sur l'ensemble de test et joignez vos résultats au rendu du TP.\n",
    "\n",
    "**Optionnel**: Vous pouvez soumettre vos résultats sur kaggle et noter votre performance en terme de log loss."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour le modèle final nous avons du bagging ce qui permet de moyenner le bruit et souvent d'avoir de meilleur resultat.\n",
    "\n",
    "## Notre logloss est de 0.78771\n",
    "On aurait pu avoir un meilleur logloss en prenant compte de lannee d'adoption ou en effectuant une transformation différente sur les ages ou en utilisant des features externes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "# parameters\n",
    "dtrain = xgb.DMatrix(X_train2, y_train_label, missing=-9999)\n",
    "dtest = xgb.DMatrix(X_test2, y_train_label, missing=-9999)\n",
    "\n",
    "param1 = {'max_depth': 7, 'eta': 0.02, 'objective': 'multi:softprob', 'num_class': 5,\n",
    "         'eval_metric': 'mlogloss', 'subsample': 0.75, 'colsample_bytree': 0.85,'silent':1}\n",
    "param2 = {'max_depth': 6, 'eta': 0.02, 'objective': 'multi:softprob', 'num_class': 5,\n",
    "\n",
    "         'eval_metric': 'mlogloss', 'subsample': 0.85, 'colsample_bytree': 0.75,'silent':1}\n",
    "param3 = {'max_depth': 8, 'eta': 0.02, 'objective': 'multi:softprob', 'num_class': 5,\n",
    "\n",
    "         'eval_metric': 'mlogloss', 'subsample': 0.65, 'colsample_bytree': 0.75,'silent':1}\n",
    "param4 = {'max_depth': 9, 'eta': 0.02, 'objective': 'multi:softprob', 'num_class': 5,\n",
    "\n",
    "         'eval_metric': 'mlogloss', 'subsample': 0.55, 'colsample_bytree': 0.65,'silent':1}\n",
    "param5 = {'max_depth': 10, 'eta': 0.02, 'objective': 'multi:softprob', 'num_class': 5,\n",
    "\n",
    "         'eval_metric': 'mlogloss', 'subsample': 0.55, 'colsample_bytree': 0.55,'silent':1}\n",
    "\n",
    "num_round=500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_1 = xgb.train(param1, dtrain, num_round)\n",
    "prediction_2 = xgb.train(param2, dtrain, num_round)\n",
    "\n",
    "prediction_3 = xgb.train(param3, dtrain, num_round)\n",
    "\n",
    "prediction_4 = xgb.train(param4, dtrain, num_round)\n",
    "\n",
    "prediction_5 = xgb.train(param5, dtrain, num_round)\n",
    "prediction = (prediction_1.predict(dtest) + prediction_2.predict(dtest) + prediction_3.predict(\n",
    "\n",
    "   dtest) + prediction_4.predict(dtest) + prediction_5.predict(dtest)) / 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test = pd.concat([ID,pd.DataFrame(prediction)],axis=1)\n",
    "pred_test.columns=['ID','Adoption','Died','Euthanasia','Return_to_owner','Transfer']\n",
    "pred_test.to_csv(\"test_prediction.csv\",index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
